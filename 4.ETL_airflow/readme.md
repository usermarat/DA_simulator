# Задание

Продолжим развивать идею из лекции и решим усложненный вариант ETL задачи. Ожидается, что на выходе будет DAG в airflow, который будет считаться каждый день за вчера. 

1. Параллельно будем обрабатывать две таблицы. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. Каждая выгрузка должна быть в отдельном таске.

2. Далее объединяем две таблицы в одну.

3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.

4. И финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse.

5. Каждый день таблица должна дополняться новыми данными. 

Структура финальной таблицы должна быть такая:

Дата - event_date

Название среза - dimension

Значение среза - dimension_value

Число просмотров - views

Число лайков - likes

Число полученных сообщений - messages_received

Число отправленных сообщений - messages_sent

От скольких пользователей получили сообщения - users_received

Скольким пользователям отправили сообщение - users_sent

Срез — это os, gender и age

Вашу таблицу необходимо загрузить в схему test, ответ на это задание — название вашей таблицы в схеме test.

# Ответ

* [скрипт с запуском DAG в Airflow](https://github.com/usermarat/DA_simulator/blob/main/4.ETL_airflow/task_6_ahmadeev.py)
* [получившаяся таблица с ежедневными данными](https://github.com/usermarat/DA_simulator/blob/main/4.ETL_airflow/task6_ahmadeev.csv)
* схема получившегося DAG:

![DAG graph](https://github.com/usermarat/DA_simulator/assets/87779469/43ba5973-b5da-408f-9e2f-795b040555ad)

* график его исполнения:

![DAG sched](https://github.com/usermarat/DA_simulator/assets/87779469/8258540b-e282-4afb-88ad-e3d82bb868c2)

